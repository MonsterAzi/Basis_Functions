C:\Users\coolm\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\torch\utils\data\dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
C:\Users\coolm\AppData\Local\Temp\ipykernel_29200\1507249952.py:51: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  return F.log_softmax(x)
Unsupported operator aten::tanh encountered 3 time(s)
Unsupported operator aten::ones_like encountered 9 time(s)
Unsupported operator aten::mul encountered 18 time(s)
Unsupported operator aten::add encountered 9 time(s)
Unsupported operator aten::log_softmax encountered 1 time(s)
Total trainable parameters of VietaPell: 105856
FLOPs of VietaPell: 106046.0
Training:   0%|          | 0/938 [00:00<?, ?it/s]C:\Users\coolm\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\LocalCache\local-packages\Python310\site-packages\torch\utils\data\dataloader.py:557: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
C:\Users\coolm\AppData\Local\Temp\ipykernel_29200\1507249952.py:51: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  return F.log_softmax(x)
Training: 100%|██████████| 938/938 [00:57<00:00, 16.30it/s, Loss=1.68, Acc=38.4]
Epoch 1/50:
Train Loss: 1.6630, Train Acc: 0.3840
Test Loss: 0.4943, Test Acc: 0.8592
Training: 100%|██████████| 938/938 [00:38<00:00, 24.25it/s, Loss=0.671, Acc=78.5]
Epoch 2/50:
Train Loss: 0.6663, Train Acc: 0.7851
Test Loss: 0.3248, Test Acc: 0.8964
Training: 100%|██████████| 938/938 [00:32<00:00, 28.58it/s, Loss=0.448, Acc=86]  
Epoch 3/50:
Train Loss: 0.4467, Train Acc: 0.8599
Test Loss: 0.2526, Test Acc: 0.9178
Training: 100%|██████████| 938/938 [00:51<00:00, 18.11it/s, Loss=0.368, Acc=88.5]
Epoch 4/50:
Train Loss: 0.3681, Train Acc: 0.8847
Test Loss: 0.2121, Test Acc: 0.9317
Training:   4%|▍         | 36/938 [00:21<09:09,  1.64it/s, Loss=0.368, Acc=88.7] 
