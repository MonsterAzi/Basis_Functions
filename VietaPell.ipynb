{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Imports and Config**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ow66s5fg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▃▅▆█</td></tr><tr><td>test_acc</td><td>▁▃▅▅█</td></tr><tr><td>test_loss</td><td>█▆▄▄▁</td></tr><tr><td>train_acc</td><td>▁▆▇██</td></tr><tr><td>train_loss</td><td>█▃▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>4</td></tr><tr><td>test_acc</td><td>0.9705</td></tr><tr><td>test_loss</td><td>0.0876</td></tr><tr><td>train_acc</td><td>0.95097</td></tr><tr><td>train_loss</td><td>0.15743</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">trim-haze-39</strong> at: <a href='https://wandb.ai/lhunos/mnist/runs/ow66s5fg' target=\"_blank\">https://wandb.ai/lhunos/mnist/runs/ow66s5fg</a><br/> View project at: <a href='https://wandb.ai/lhunos/mnist' target=\"_blank\">https://wandb.ai/lhunos/mnist</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240923_015350-ow66s5fg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:ow66s5fg). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: /sys/module/amdgpu/initstate: No such file or directory\n",
      "ERROR:root:Driver not initialized (amdgpu not found in modules)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/azazelleg/AI/Basis_Functions/wandb/run-20240923_015442-oq42pfxl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/lhunos/mnist/runs/oq42pfxl' target=\"_blank\">distinctive-firefly-40</a></strong> to <a href='https://wandb.ai/lhunos/mnist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/lhunos/mnist' target=\"_blank\">https://wandb.ai/lhunos/mnist</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/lhunos/mnist/runs/oq42pfxl' target=\"_blank\">https://wandb.ai/lhunos/mnist/runs/oq42pfxl</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, cohen_kappa_score, accuracy_score, classification_report, confusion_matrix\n",
    "from dataclasses import dataclass\n",
    "from fvcore.nn import FlopCountAnalysis\n",
    "import wandb\n",
    "from soap import SOAP\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    batch_size: int = 128\n",
    "    learning_rate: float = 1.73e-3\n",
    "    epochs: int = 50\n",
    "    patience: int = 10\n",
    "    num_workers: int = 10\n",
    "    rotation: int = 5\n",
    "    translation: float = 0.1\n",
    "    shear_angle: int = 1\n",
    "\n",
    "# Initialize wandb\n",
    "run = wandb.init(\n",
    "    # Set the project where this run will be logged\n",
    "    project=\"mnist\",\n",
    "    # Track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"batch_size\": Config.batch_size,\n",
    "        \"learning_rate\": Config.learning_rate,\n",
    "        \"epochs\": Config.epochs,\n",
    "        \"patience\": Config.patience,\n",
    "        \"num_workers\": Config.num_workers,\n",
    "        \"rotation\": Config.rotation,\n",
    "        \"translation\": Config.translation,\n",
    "        \"shear_angle\": Config.shear_angle\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Network Definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vieta_pell(n, x):\n",
    "    if n == 0:\n",
    "        return 2 * torch.ones_like(x)\n",
    "    elif n == 1:\n",
    "        return x\n",
    "    else:\n",
    "        return x * vieta_pell(n - 1, x) + vieta_pell(n - 2, x)\n",
    "\n",
    "class VietaPellKANLayer(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, degree):\n",
    "        super(VietaPellKANLayer, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.degree = degree\n",
    "        self.vp_coeffs = nn.Parameter(torch.empty(input_dim, output_dim, degree + 1))\n",
    "        nn.init.normal_(self.vp_coeffs, mean=0.0, std=1 / (input_dim * (degree + 1)))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Normalize x to [-1, 1] using tanh\n",
    "        x = torch.tanh(x)\n",
    "\n",
    "        # Compute the Vieta-Pell basis functions\n",
    "        vp_basis = []\n",
    "        for n in range(self.degree + 1):\n",
    "            vp_basis.append(vieta_pell(n, x))\n",
    "        vp_basis = torch.stack(vp_basis, dim=-1)  # shape = (batch_size, input_dim, degree + 1)\n",
    "\n",
    "        # Compute the Vieta-Pell interpolation\n",
    "        y = torch.einsum(\"bid,iod->bo\", vp_basis, self.vp_coeffs)  # shape = (batch_size, output_dim)\n",
    "        y = y.view(-1, self.output_dim)\n",
    "\n",
    "        return y\n",
    "\n",
    "class MNISTVietaPellKAN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MNISTVietaPellKAN, self).__init__()\n",
    "        self.trigkan1 = VietaPellKANLayer(784, 32, 3)\n",
    "        self.bn1 = nn.LayerNorm(32)\n",
    "        self.trigkan2 = VietaPellKANLayer(32, 32, 3)\n",
    "        self.bn2 = nn.LayerNorm(32)\n",
    "        self.trigkan3 = VietaPellKANLayer(32, 10, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        #x=x.tanh()\n",
    "        x = self.trigkan1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.trigkan2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.trigkan3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training and Testing Defintion**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.RandomAffine(degrees=Config.rotation, translate=(Config.translation, Config.translation), shear=Config.shear_angle),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "transform_test = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=Config.batch_size, shuffle=True, num_workers=Config.num_workers)\n",
    "test_loader = DataLoader(test_dataset, batch_size=Config.batch_size, shuffle=False, num_workers=Config.num_workers)\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "\n",
    "def train(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=\"Training\")\n",
    "    for data, target in progress_bar:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        _, predicted = output.max(1)\n",
    "        total += target.size(0)\n",
    "        correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "        progress_bar.set_postfix({'Loss': total_loss / (progress_bar.n + 1), 'Acc': 100. * correct / total})\n",
    "    \n",
    "    return total_loss / len(train_loader), correct / total\n",
    "\n",
    "def validate(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            total_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "\n",
    "    return total_loss / len(test_loader), correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Set-up**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::tanh encountered 3 time(s)\n",
      "Unsupported operator aten::ones_like encountered 9 time(s)\n",
      "Unsupported operator aten::mul encountered 18 time(s)\n",
      "Unsupported operator aten::add encountered 9 time(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trainable parameters of VietaPell: 105856\n",
      "FLOPs of VietaPell: 106046.0\n"
     ]
    }
   ],
   "source": [
    "Model_Name='VietaPell'  #Add names of other models\n",
    "model0 = MNISTVietaPellKAN().to(device)\n",
    "model=model0\n",
    "total_params = sum(p.numel() for p in model0.parameters() if p.requires_grad)\n",
    "flops = FlopCountAnalysis(model, inputs=(torch.randn(1, 28 * 28).to(device),)).total()\n",
    "print(f\"Total trainable parameters of {Model_Name}: {total_params}\")\n",
    "print(f\"FLOPs of {Model_Name}: {flops}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training of Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 169.69it/s, Loss=0.576, Acc=83.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:\n",
      "Train Loss: 0.5567, Train Acc: 0.8335\n",
      "Test Loss: 0.1795, Test Acc: 0.9441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 176.43it/s, Loss=0.26, Acc=92.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50:\n",
      "Train Loss: 0.2477, Train Acc: 0.9223\n",
      "Test Loss: 0.1419, Test Acc: 0.9544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 169.87it/s, Loss=0.206, Acc=93.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50:\n",
      "Train Loss: 0.2012, Train Acc: 0.9377\n",
      "Test Loss: 0.1300, Test Acc: 0.9580\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 169.68it/s, Loss=0.194, Acc=94.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50:\n",
      "Train Loss: 0.1862, Train Acc: 0.9419\n",
      "Test Loss: 0.1059, Test Acc: 0.9675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 172.37it/s, Loss=0.171, Acc=94.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50:\n",
      "Train Loss: 0.1703, Train Acc: 0.9457\n",
      "Test Loss: 0.1035, Test Acc: 0.9668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 177.16it/s, Loss=0.166, Acc=95]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50:\n",
      "Train Loss: 0.1593, Train Acc: 0.9502\n",
      "Test Loss: 0.0975, Test Acc: 0.9691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 175.66it/s, Loss=0.149, Acc=95.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50:\n",
      "Train Loss: 0.1491, Train Acc: 0.9534\n",
      "Test Loss: 0.0963, Test Acc: 0.9685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 176.84it/s, Loss=0.147, Acc=95.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50:\n",
      "Train Loss: 0.1412, Train Acc: 0.9567\n",
      "Test Loss: 0.0876, Test Acc: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 175.84it/s, Loss=0.139, Acc=95.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50:\n",
      "Train Loss: 0.1341, Train Acc: 0.9576\n",
      "Test Loss: 0.0971, Test Acc: 0.9676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 179.92it/s, Loss=0.136, Acc=95.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50:\n",
      "Train Loss: 0.1337, Train Acc: 0.9583\n",
      "Test Loss: 0.0842, Test Acc: 0.9743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 177.19it/s, Loss=0.134, Acc=96]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50:\n",
      "Train Loss: 0.1290, Train Acc: 0.9599\n",
      "Test Loss: 0.0793, Test Acc: 0.9743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 177.62it/s, Loss=0.128, Acc=96.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50:\n",
      "Train Loss: 0.1232, Train Acc: 0.9609\n",
      "Test Loss: 0.0781, Test Acc: 0.9746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 173.28it/s, Loss=0.125, Acc=96.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50:\n",
      "Train Loss: 0.1227, Train Acc: 0.9617\n",
      "Test Loss: 0.0790, Test Acc: 0.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 175.34it/s, Loss=0.119, Acc=96.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50:\n",
      "Train Loss: 0.1179, Train Acc: 0.9628\n",
      "Test Loss: 0.0722, Test Acc: 0.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 176.55it/s, Loss=0.123, Acc=96.3]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50:\n",
      "Train Loss: 0.1182, Train Acc: 0.9635\n",
      "Test Loss: 0.0741, Test Acc: 0.9749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 176.21it/s, Loss=0.119, Acc=96.4]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50:\n",
      "Train Loss: 0.1140, Train Acc: 0.9639\n",
      "Test Loss: 0.0713, Test Acc: 0.9771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 174.72it/s, Loss=0.114, Acc=96.6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50:\n",
      "Train Loss: 0.1107, Train Acc: 0.9657\n",
      "Test Loss: 0.0720, Test Acc: 0.9760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 175.56it/s, Loss=0.117, Acc=96.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50:\n",
      "Train Loss: 0.1119, Train Acc: 0.9650\n",
      "Test Loss: 0.0776, Test Acc: 0.9746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 176.13it/s, Loss=0.108, Acc=96.5]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50:\n",
      "Train Loss: 0.1076, Train Acc: 0.9652\n",
      "Test Loss: 0.0716, Test Acc: 0.9763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 175.68it/s, Loss=0.106, Acc=96.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50:\n",
      "Train Loss: 0.1056, Train Acc: 0.9673\n",
      "Test Loss: 0.0734, Test Acc: 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 173.44it/s, Loss=0.108, Acc=96.7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50:\n",
      "Train Loss: 0.1056, Train Acc: 0.9672\n",
      "Test Loss: 0.0665, Test Acc: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 174.78it/s, Loss=0.106, Acc=96.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50:\n",
      "Train Loss: 0.1049, Train Acc: 0.9678\n",
      "Test Loss: 0.0653, Test Acc: 0.9787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 173.97it/s, Loss=0.103, Acc=96.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50:\n",
      "Train Loss: 0.1005, Train Acc: 0.9680\n",
      "Test Loss: 0.0703, Test Acc: 0.9771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 174.79it/s, Loss=0.103, Acc=96.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50:\n",
      "Train Loss: 0.1018, Train Acc: 0.9679\n",
      "Test Loss: 0.0637, Test Acc: 0.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 176.44it/s, Loss=0.101, Acc=96.8] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50:\n",
      "Train Loss: 0.1008, Train Acc: 0.9682\n",
      "Test Loss: 0.0693, Test Acc: 0.9786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 172.70it/s, Loss=0.1, Acc=96.8]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50:\n",
      "Train Loss: 0.0994, Train Acc: 0.9684\n",
      "Test Loss: 0.0678, Test Acc: 0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 174.21it/s, Loss=0.0984, Acc=97] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50:\n",
      "Train Loss: 0.0980, Train Acc: 0.9700\n",
      "Test Loss: 0.0671, Test Acc: 0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 175.16it/s, Loss=0.0977, Acc=96.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50:\n",
      "Train Loss: 0.0977, Train Acc: 0.9692\n",
      "Test Loss: 0.0674, Test Acc: 0.9775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 172.72it/s, Loss=0.099, Acc=97]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50:\n",
      "Train Loss: 0.0975, Train Acc: 0.9699\n",
      "Test Loss: 0.0670, Test Acc: 0.9783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 176.73it/s, Loss=0.101, Acc=97]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50:\n",
      "Train Loss: 0.0963, Train Acc: 0.9705\n",
      "Test Loss: 0.0591, Test Acc: 0.9800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 175.58it/s, Loss=0.0983, Acc=97]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50:\n",
      "Train Loss: 0.0939, Train Acc: 0.9705\n",
      "Test Loss: 0.0655, Test Acc: 0.9782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 174.96it/s, Loss=0.0946, Acc=97]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50:\n",
      "Train Loss: 0.0944, Train Acc: 0.9697\n",
      "Test Loss: 0.0658, Test Acc: 0.9789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:03<00:00, 156.27it/s, Loss=0.0988, Acc=97]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50:\n",
      "Train Loss: 0.0939, Train Acc: 0.9699\n",
      "Test Loss: 0.0647, Test Acc: 0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 173.86it/s, Loss=0.0962, Acc=97]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50:\n",
      "Train Loss: 0.0941, Train Acc: 0.9702\n",
      "Test Loss: 0.0607, Test Acc: 0.9809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 175.01it/s, Loss=0.0926, Acc=97.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50:\n",
      "Train Loss: 0.0920, Train Acc: 0.9713\n",
      "Test Loss: 0.0600, Test Acc: 0.9801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 174.53it/s, Loss=0.0929, Acc=97.1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50:\n",
      "Train Loss: 0.0923, Train Acc: 0.9707\n",
      "Test Loss: 0.0606, Test Acc: 0.9792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 175.79it/s, Loss=0.0905, Acc=97.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50:\n",
      "Train Loss: 0.0903, Train Acc: 0.9718\n",
      "Test Loss: 0.0640, Test Acc: 0.9790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 174.64it/s, Loss=0.092, Acc=97.2] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50:\n",
      "Train Loss: 0.0908, Train Acc: 0.9719\n",
      "Test Loss: 0.0661, Test Acc: 0.9791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 175.15it/s, Loss=0.0884, Acc=97.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50:\n",
      "Train Loss: 0.0880, Train Acc: 0.9720\n",
      "Test Loss: 0.0617, Test Acc: 0.9803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 469/469 [00:02<00:00, 176.53it/s, Loss=0.0906, Acc=97.2]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50:\n",
      "Train Loss: 0.0906, Train Acc: 0.9718\n",
      "Test Loss: 0.0612, Test Acc: 0.9792\n",
      "Early stopping after 40 epochs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>test_acc</td><td>▁▃▄▅▅▆▆▆▅▇▇▇▇▇▇▇▇▇▇▇██▇███▇▇██▇█████████</td></tr><tr><td>test_loss</td><td>█▆▅▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_acc</td><td>▁▅▆▆▇▇▇▇▇▇▇▇▇███████████████████████████</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>39</td></tr><tr><td>test_acc</td><td>0.9792</td></tr><tr><td>test_loss</td><td>0.06119</td></tr><tr><td>train_acc</td><td>0.97185</td></tr><tr><td>train_loss</td><td>0.09059</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">distinctive-firefly-40</strong> at: <a href='https://wandb.ai/lhunos/mnist/runs/oq42pfxl' target=\"_blank\">https://wandb.ai/lhunos/mnist/runs/oq42pfxl</a><br/> View project at: <a href='https://wandb.ai/lhunos/mnist' target=\"_blank\">https://wandb.ai/lhunos/mnist</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240923_015442-oq42pfxl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.18.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VietaPell processing time: 0.06 seconds\n"
     ]
    }
   ],
   "source": [
    "def train_and_validate(model, train_loader, test_loader, criterion, optimizer, device, epochs, patience):\n",
    "    best_test_loss = float('inf')\n",
    "    best_weights = None\n",
    "    no_improve = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_loss, train_acc = train(model, train_loader, criterion, optimizer, device)\n",
    "        test_loss, test_acc = validate(model, test_loader, criterion, device)\n",
    "\n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": train_loss,\n",
    "            \"train_acc\": train_acc,\n",
    "            \"test_loss\": test_loss,\n",
    "            \"test_acc\": test_acc\n",
    "        }, step=epoch+1)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{epochs}:')\n",
    "        print(f'Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        print(f'Test Loss: {test_loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "        \n",
    "        if test_loss < best_test_loss:\n",
    "            best_test_loss = test_loss\n",
    "            best_weights = model.state_dict()\n",
    "            no_improve = 0\n",
    "        else:\n",
    "            no_improve += 1\n",
    "            if no_improve == patience:\n",
    "                print(f'Early stopping after {epoch+1} epochs')\n",
    "                break\n",
    "    \n",
    "    return best_weights, best_test_loss\n",
    "\n",
    "\n",
    "optimizers = SOAP(model.parameters(), lr=Config.learning_rate)\n",
    "\n",
    "best_weights, model_times = train_and_validate(model, train_loader, test_loader, criterion, optimizers, device, Config.epochs, Config.patience)\n",
    "\n",
    "wandb.finish()\n",
    "\n",
    "# Save the best weights for model\n",
    "model.load_state_dict(best_weights)\n",
    "torch.save(model.state_dict(), f'{Model_Name}_best_weights.pth')\n",
    "\n",
    "# Print the processing time for model\n",
    "print(f\"{Model_Name} processing time: {model_times:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99       980\n",
      "           1       0.99      0.99      0.99      1135\n",
      "           2       0.98      0.98      0.98      1032\n",
      "           3       0.97      0.97      0.97      1010\n",
      "           4       0.98      0.97      0.98       982\n",
      "           5       0.98      0.97      0.98       892\n",
      "           6       0.98      0.98      0.98       958\n",
      "           7       0.98      0.98      0.98      1028\n",
      "           8       0.98      0.97      0.98       974\n",
      "           9       0.96      0.97      0.97      1009\n",
      "\n",
      "    accuracy                           0.98     10000\n",
      "   macro avg       0.98      0.98      0.98     10000\n",
      "weighted avg       0.98      0.98      0.98     10000\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 35\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Usage\u001b[39;00m\n\u001b[1;32m     34\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(best_weights)\n\u001b[0;32m---> 35\u001b[0m accuracy, f1, kappa \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, F1 Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf1\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Cohen\u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124ms Kappa: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkappa\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 25\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, test_loader, device)\u001b[0m\n\u001b[1;32m     23\u001b[0m cm \u001b[38;5;241m=\u001b[39m confusion_matrix(all_targets, all_preds)\n\u001b[1;32m     24\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m---> 25\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mheatmap(cm, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBlues\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConfusion Matrix\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     27\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrue Label\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_targets = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data = data.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "            all_targets.extend(target.numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(all_targets, all_preds)\n",
    "    f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "    kappa = cohen_kappa_score(all_targets, all_preds)\n",
    "    \n",
    "    # Print classification report\n",
    "    print(classification_report(all_targets, all_preds))\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    cm = confusion_matrix(all_targets, all_preds)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "    \n",
    "    return accuracy, f1, kappa\n",
    "\n",
    "# Usage\n",
    "model.load_state_dict(best_weights)\n",
    "accuracy, f1, kappa = evaluate_model(model, test_loader, device)\n",
    "print(f'Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Cohen\\'s Kappa: {kappa:.4f}')\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ISPRS-2020-HyperspectralChange DetectionUSA.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
